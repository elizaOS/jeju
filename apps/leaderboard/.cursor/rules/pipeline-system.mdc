---
description: 
globs: src/lib/pipelines/*,cli/analyze-pipeline.ts
alwaysApply: false
---
# TypeScript Pipeline System

- **Core Architecture**
  - The pipeline system follows a functional programming approach with composable operations
pipeline consists of typed, chainable steps that transform data
  - Pipeline state is managh a shared context object passed between steps
  - File-based organization separates concerns by pipeline type (ingest, export, summarize, etc.)

The cli program that runs the pipelines is in @analyze-pipeline.ts

- **Basic Usage**
  ```bash
  # ✅ DO: Use built-in pipeline commands with appropriate flags
  bun run pipeline ingest --after 2025-01-01 --before 2025-01-31
  bun run pipeline process --force
  bun run pipeline export --days 90
  bun run pipeline summarize --all

  # ❌ DON'T: Execute pipeline mrectly
  bun src/lib/pipelines/ing

- **Command Options**
  - All data-processing commands support consistent date range options:
    - `--after YYYY-MM-DD`: Specify a start date
    - `--before YYYY-MM-DD`: Specify an end date (defaults to today)
    - `--days NUMBER`: Specify lookback period from end date
    - `--all`: all data since contributionStar-force`: Recalculate and overwng data

- **Default Lookbods**
  - `ingest`: 7 days
  - `export`: 30 days
  - `summarize`: 7 days

- **Configuration**
  - Pipeline s in @pipel - Configurable aspects include:
    - Repositories to track
    - Scoring rules for contribution types
    - Tag definitions and weights
    - Bot user exclusion list
    - AI summarization settings

- **Pipeline Components**
  - **Core Utilities**
    ```typescript
    // ✅ DO: Use the typed pipeline utilities for composition
    import { pipe, parallel, mapStep, createStep } from "../types";
    
    // Create a typed step with proper logging
    const fetchData = createStep<MyContext>("fetchData", async (ctx) => {
      // Implementation
      return ctx;
    });
    
    // Compose steps
    const myPipeline = pipe(
      fetchData,
      parallel(processA, processB),
      saveResults
    );
    
    // ❌ DON'T: Create untyped functicontext pattern
    const badStep = async (data: any) => {
      // Direct data manipulation without context
      return transformedData;
    };
    ```

- **Configuration and Customization**
  - All scoring, tagging, and repository settings should be defined in @pipelineConfig.ts
  - Use Zod schemas for config valide config structure:
    ```typescripteConfigSchema = z.object({
      repositories: z.array(RepositoryConfigSchema),
      scoring: ScoringConfigSchema,
      tags: ...,
      ...
    });
    ```
- *onents**
  - @types.ts: Pipeline type definitions and core utilities
  - @pipelineConfig.ts: Configuration schemas and types
  - @queryHelpers.ts: SQL query builder helpers
  - @db.ts : Database connection and configuration
  - @schema.ts: Database schema with relations
- @generateTimeIntervals.ts – Time interval utilities
  - @getActiveContributors.ts Pipeline steps for fetching contributors with activity in time interval
  - @getSelectedRepositories.ts Pipeline step for loading repo info from database

- **Creating New Pipelines**
  ```typescript
  // ✅ DO: Fohed pipeline pattern
  // 1. Create a context type extending the base
  interface MyPipelineContext extends BasePipelineContext {
    myData: MyDataType[];
    config: MyConfigType;
  }
  
  // 2. Create steps with createStep
 ep1 = createStep<MyPipelineContext>("step1", asy// Implementation
    return       myData: proce  // 3. Compose pipeline with pline = pipe(
    initializeContext,
    step1,
    step2,
    finalizeResultspipeline and non-pipeline patterns
  export async funct) {
    const data = await fetchDirectly();
    // Miggingretur(data);
  }
  ```

- **Time-based Operations**
  - Use @generateTimeIntervals.ts for date range operations
  - Time intervals can be daily, weekly, or monthly
  - See implementations in @summarize/index.ts for examples

- **Database Operations**
  - Use the query helpers from @queryHelpers.ts
  - Follow the @database-queries rule for Drizzle ORM usage
  ```typescript
  // ✅ DO: Use the typed query helpers
  import { createDateRangeQuery } from "../queryHelpers";
  
  const query = createDateRangeQuery({
    table: schema.contributions,
    dateField: "createdAt",
    startDate: ctx.startDate,
    endDate: ctx.endDate
  });
  
  // ❌ DON'T: Write raw SQL or bypass the query helpers
  const results = await db.query(`
    SELECT * FROM contributions 
    WHERE created_at > '${startDate}' AND created_at < '${endDate}'
  `);
  ```

- **Error Handling**
  ```typescript
  // ✅ DO: Let the pipeline handle errors via createStep
  const safeStep = createStep<MyContext>("safeStep", async (ctx) => {
    try {
      // Implementation
      return { ...ctx, results };
    } catch (error) {
      ctx.logger.error("Failed during safeStep", { error });
      // Return context to continue pipeline
      return ctx;
    }
  });
  
  // ❌ DON'T: Throw errors that terminate the pipeline unexpectedly
  const riskyStep = createStep<MyContext>("riskyStep", async (ctx) => {
    // Throws error with no handling
    const data = JSON.parse(malformedData);
    return { ...ctx, data };
  });
  ```

- **Pipeline Structure and Key Files**
  - Organize each major pipeline in its own directory under `src/lib/pipelines/`
    - @ingest/ – GitHub data ingestion
    - @contributors/ – Contributor analysis
    - @summarize/ – AI summarization
    - @export/ – Data/statistics export
  - Each pipeline should export a main composed pipeline from its `index.ts` (see @summarize/index.ts)
  - Use @runPipeline.ts to execute pipelines with error handling and logging

- **Creating and Extending Pipelines**
  - To create a new pipeline:
    1. Create a new directory under `src/lib/pipelines/`
    2. Define a context type extending `BasePipelineContext`
    3. Define each pipeline step as a typed function: `(input, context) => output | Promise<output>` (@types.ts), or use `createStep()`
  4. Compose steps using `pipe()`, `parallel()`, `sequence()`, and `mapStep()` utilities (@types.ts)
  - Example:
    ```typescript
    // ✅ DO: Compose steps for clarity and reuse
    const pipeline = pipe(
      stepA,
      mapStep(stepB),
      createStep("finalize", (result, ctx) => result)
    );
    ```
    ```typescript
    // ❌ DON'T: Write monolithic, untyped, or side-effect-heavy pipeline logic
    async function run() {
      // ...all logic in one place
    }
    ```
    
    5. Export the composed pipeline from `index.ts`
  
   6. Update @analyze-pipeline.ts with a new command or necesarry changes to the actual pipeline CLI code that imports and runs the pipelines


- **Testing and Logging**
  - Prefer Bun's test runner for pipeline step/unit tests
  - Use the logger in context for all step-level logging
  - Example:
    ```typescript
    context.logger?.info('Step completed', { details });
    ```


- **DO**
  - Use type inference and Zod schemas for all config and step inputs/outputs
  - Keep steps pure and side-effect free except for explicit DB/file/logging actions
  - Reference and reuse existing steps/utilities before creating new ones
  - Document new pipeline patterns in this rule if used in 3+ places (@self_improve.mdc)
- **DON'T**
  - Don't hardcode config or repo IDs in pipeline logic
  - Don't bypass context/config in step signatures
  - Don't duplicate logic already present in helpers/utilities
- **Performance Considerations**
  - Use `parallel()` for independent operations
  - Use `sequence()` to run steps in order, especially if the sub steps loop over many items.
  - Consider chunking for large data sets using generateTimeInterval or manual chunking if not time-based styps
  - Add progress reporting for long-running steps
  - Cache intermediate results when appropriate