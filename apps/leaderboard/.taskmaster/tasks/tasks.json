{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Set up project structure and core dependencies",
        "description": "Initialize the project repository with the necessary folder structure and install all required dependencies.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Create the project repository with the following structure: `/src/lib/data`, `/src/lib/pipelines`, `/src/app`, `/cli`, `/config`, `/drizzle`, `/data`. Initialize with Bun (`bun init`) and install core dependencies: Next.js 14+, Drizzle ORM, shadcn/ui, SQLite, and any utility libraries. Set up TypeScript configuration with appropriate tsconfig.json. Create initial package.json with scripts for running the pipeline, database operations, and Next.js commands.",
        "testStrategy": "Verify all dependencies install correctly without conflicts. Ensure the project structure is created as specified. Test basic commands like `bun run` to confirm the setup is working."
      },
      {
        "id": 2,
        "title": "Define core data types and interfaces",
        "description": "Create TypeScript types and interfaces for all data models used throughout the application.",
        "status": "done",
        "dependencies": [1],
        "priority": "high",
        "details": "Create `src/lib/data/types.ts` with interfaces for: Repository, Contributor, PullRequest, Issue, Review, Comment, Reaction, TagRule, TagPattern, UserTagScore, Summary, and Stats. Include appropriate properties for each interface based on the data model descriptions in the PRD. Define enums for status values, reaction types, and other categorical data. Create utility types for configuration objects that will be used in the pipeline configuration file.",
        "testStrategy": "Review the type definitions for completeness against the PRD requirements. Ensure all required properties are included and properly typed. Verify that the types are exported correctly for use in other modules."
      },
      {
        "id": 3,
        "title": "Implement database schema and ORM setup",
        "description": "Define the SQLite database schema using Drizzle ORM and set up database connection utilities.",
        "status": "done",
        "dependencies": [2],
        "priority": "high",
        "details": "Create `src/lib/data/schema.ts` to define all database tables using Drizzle's schema definition syntax. Tables should include: repositories, contributors, pullRequests, issues, reviews, comments, reactions, tagRules, and userTagScores. Define appropriate columns, primary keys, foreign keys, and indexes. Create `src/lib/data/db.ts` to handle database connection and provide a reusable DB client. Implement functions for database initialization and basic CRUD operations. Set up Drizzle migration scripts in package.json (`db:generate`, `db:migrate`, `db:studio`).",
        "testStrategy": "Generate and apply an initial migration to verify the schema is valid. Test database connection and basic CRUD operations with sample data. Verify that all tables are created with the correct structure and relationships."
      },
      {
        "id": 4,
        "title": "Create GitHub API interaction module",
        "description": "Implement a module to interact with GitHub's GraphQL API for fetching repository data.",
        "status": "done",
        "dependencies": [2],
        "priority": "high",
        "details": "Create `src/lib/data/github.ts` to handle all GitHub API interactions. Implement functions to fetch pull requests, issues, reviews, comments, and reactions using the GitHub GraphQL API. Include pagination handling to retrieve all data. Implement rate limit awareness and backoff strategies. Create utility functions to transform the raw GitHub API responses into the application's data models. Add environment variable handling for the GitHub token (`GITHUB_TOKEN`). Include filtering logic to exclude bot users as specified in the configuration.",
        "testStrategy": "Test API calls with a valid GitHub token against a test repository. Verify that all data types are correctly fetched and transformed. Test pagination by fetching a large dataset. Verify rate limit handling by monitoring API usage during tests."
      },
      {
        "id": 5,
        "title": "Implement pipeline configuration system",
        "description": "Create the configuration system for defining repositories, scoring rules, and other pipeline settings.",
        "status": "done",
        "dependencies": [2],
        "priority": "high",
        "details": "Create `config/pipeline.config.ts` to define the configuration schema and default values. Implement configuration for: repositories to track, bot users to ignore, AI summary settings (enabled flag, API keys, models), and TagRule definitions with patterns and scoring logic. Create a configuration loader that validates the configuration and provides type-safe access to settings. Implement a system to override configuration values using environment variables where appropriate. Document the configuration options and format in comments.",
        "testStrategy": "Create a test configuration and verify it loads correctly. Test validation by introducing invalid configurations and ensuring appropriate errors are thrown. Verify environment variable overrides work as expected."
      },
      {
        "id": 6,
        "title": "Develop data ingestion pipeline",
        "description": "Implement the pipeline step for ingesting data from GitHub and storing it in the database.",
        "status": "done",
        "dependencies": [3, 4, 5],
        "priority": "high",
        "details": "Create `src/lib/pipelines/ingest/index.ts` to implement the ingestion pipeline. Use the GitHub API module to fetch data for configured repositories. Implement logic to determine the date range for fetching (either specified or since last fetch). Store the fetched data in the SQLite database using the Drizzle ORM. Implement deduplication logic to avoid storing duplicate events. Add logging to track progress and any issues during ingestion. Implement error handling and retries for API failures.",
        "testStrategy": "Test the ingestion pipeline with a small repository to verify data is correctly fetched and stored. Verify incremental fetching works by running the pipeline multiple times. Check that bot users are correctly filtered out based on configuration."
      },
      {
        "id": 7,
        "title": "Implement scoring engine and rules processing",
        "description": "Create the scoring engine that applies TagRules to calculate contributor scores based on their activity.",
        "status": "done",
        "dependencies": [3, 5, 6],
        "priority": "high",
        "details": "Create `src/lib/pipelines/contributors/scoring.ts` to implement the scoring engine. Develop pattern matching logic to apply TagRules to different content types (file paths, commit messages, PR titles, etc.). Implement score calculation based on matched patterns, including handling of multipliers, caps, and other modifiers. Create functions to update the userTagScores table with calculated scores. Implement logic to handle score accumulation over time, potentially with decay or other time-based adjustments. Add detailed logging for score calculations to aid in debugging and transparency.",
        "testStrategy": "Create test TagRules and sample contribution data. Verify that patterns match correctly and scores are calculated as expected. Test edge cases like very high activity, no matches, and multiple rule matches. Verify that scores are correctly stored and updated in the database."
      },
      {
        "id": 8,
        "title": "Build data processing pipeline",
        "description": "Implement the main processing pipeline that analyzes ingested data and applies scoring rules.",
        "status": "done",
        "dependencies": [7],
        "priority": "high",
        "details": "Create `src/lib/pipelines/contributors/index.ts` to implement the main processing pipeline. Integrate the scoring engine to process all contributors and their activities. Implement logic to calculate aggregate statistics for repositories and time periods. Create functions to identify expertise areas based on tag scores. Implement any additional analysis required for the frontend display. Ensure the pipeline can be run incrementally to process only new data since the last run. Add progress reporting and error handling.",
        "testStrategy": "Test the processing pipeline with sample data to verify it correctly analyzes and scores contributions. Verify incremental processing works correctly. Check that all required statistics and derived data are calculated and stored properly."
      },
      {
        "id": 9,
        "title": "Create data export functionality",
        "description": "Implement the pipeline step for exporting processed data to JSON files for frontend consumption.",
        "status": "done",
        "dependencies": [8],
        "priority": "medium",
        "details": "Create `src/lib/pipelines/export/index.ts` to implement the export pipeline. Query the database for processed data within specified date ranges. Generate JSON files organized by repository and time interval (daily, weekly, monthly). Implement file structure as specified in the PRD (e.g., `data/elizaos_eliza/day/stats/stats_2024-01-01.json`). Ensure exported data includes all necessary information for the frontend. Add options to control which data types and time periods are exported. Implement error handling and logging.",
        "testStrategy": "Test the export pipeline with processed data to verify JSON files are correctly generated with the expected structure. Verify all required data is included in the exports. Check that the file organization matches the specified structure."
      },
      {
        "id": 10,
        "title": "Develop CLI interface for pipeline steps",
        "description": "Create a command-line interface to run individual pipeline steps and manage the overall workflow.",
        "status": "done",
        "dependencies": [6, 8, 9],
        "priority": "medium",
        "details": "Create `cli/analyze-pipeline.ts` to implement the CLI interface. Use a command-line argument parsing library to handle commands and options. Implement commands for each pipeline step: `ingest`, `process` (or `score`), `export`, and placeholders for future commands like `summarize`. Add options for specifying date ranges, repositories, and other parameters. Implement help text and usage examples. Create a combined command to run the full pipeline in sequence. Add error handling and logging for all commands.",
        "testStrategy": "Test each CLI command with various options to verify they work as expected. Test the full pipeline command to ensure all steps run in the correct sequence. Verify error handling by testing with invalid inputs and checking that appropriate error messages are displayed."
      },
      {
        "id": 11,
        "title": "Set up Next.js application structure",
        "description": "Initialize the Next.js frontend application with routing, layout, and component structure.",
        "status": "done",
        "dependencies": [1],
        "priority": "medium",
        "details": "Set up the Next.js application in `src/app` using the App Router. Create the main layout with navigation components. Implement shadcn/ui for styling and components. Set up utility functions for loading and parsing the exported JSON data. Create reusable components for common UI elements like contributor cards, score displays, and activity timelines. Implement responsive design for different screen sizes. Set up static site generation configuration for deployment.",
        "testStrategy": "Verify the Next.js application builds successfully. Test navigation between pages. Check that the layout and components render correctly on different screen sizes. Verify that utility functions correctly load and parse JSON data."
      },
      {
        "id": 12,
        "title": "Implement leaderboard and profile pages",
        "description": "Create the main leaderboard page and individual contributor profile pages.",
        "status": "done",
        "dependencies": [9, 11],
        "priority": "medium",
        "details": "Implement the leaderboard page at `/leaderboard` to display ranked contributors based on scores. Include filtering options for time periods (daily, weekly, monthly, all-time). Create contributor profile pages at `/profile/[username]` to show detailed information about individual contributors. Include score breakdown, activity timeline, expertise tags, and historical contribution data. Implement data loading from the exported JSON files. Add sorting and filtering options for the leaderboard. Ensure all pages are statically generated during build.",
        "testStrategy": "Test the leaderboard page with sample data to verify contributors are correctly ranked and displayed. Test profile pages for different contributors to ensure all information is correctly shown. Verify filtering and sorting options work as expected. Check that pages are correctly generated during the build process."
      },
      {
        "id": 13,
        "title": "Implement AI summary generation",
        "description": "Create the pipeline step for generating AI-powered summaries of project and contributor activity.",
        "status": "done",
        "dependencies": [9],
        "priority": "medium",
        "details": "Create `src/lib/pipelines/summarize/index.ts` to implement the summary generation pipeline. Implement integration with OpenRouter API for AI model access. Create prompts for project summaries and contributor summaries. Implement logic to gather relevant data for summarization (PR titles, issue summaries, key stats). Add configuration options for AI models per time interval. Implement caching to avoid regenerating summaries unnecessarily. Save generated summaries as JSON files in the specified structure. Add error handling and retries for API failures.",
        "testStrategy": "Test summary generation with sample data to verify summaries are correctly generated and saved. Test with different AI models to ensure compatibility. Verify error handling by simulating API failures. Check that the generated summaries are informative and accurate based on the input data."
      },
      {
        "id": 14,
        "title": "Implement daily, weekly, and monthly report views",
        "description": "Create pages for viewing aggregated statistics and AI-generated summaries for different time periods.",
        "status": "pending",
        "dependencies": [12, 13],
        "priority": "low",
        "details": "Implement report view pages for daily (`/daily/[[...date]]`), weekly, and monthly periods. Create components to display aggregated statistics for each time period. Integrate AI-generated summaries into the report views. Implement navigation between different time periods. Add visualizations for key metrics using appropriate charting libraries. Ensure all pages are statically generated during build. Implement fallbacks for missing data or summaries.",
        "testStrategy": "Test report views with sample data to verify statistics and summaries are correctly displayed. Test navigation between different time periods. Verify visualizations render correctly with different data sets. Check that pages are correctly generated during the build process.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement weekly report view page and components",
            "description": "Create the weekly report view page with aggregated statistics and AI-generated summaries for weekly time periods.",
            "dependencies": [],
            "details": "1. Create a new page at `/weekly/[[...date]]` that accepts an optional date parameter.\n2. Implement the page layout with sections for statistics and summary content.\n3. Create a data fetching function to retrieve weekly aggregated statistics based on the provided date (or default to current week).\n4. Implement a component to render the weekly summary markdown from `data/<repoName>/summaries/week/yyyy-mm-dd.md` using react-markdown or Next.js MDX support.\n5. Add navigation controls to move between different weeks.\n6. Create visualization components for key weekly metrics using an appropriate charting library.\n7. Implement fallback UI for missing data or summaries.\n8. Ensure the page is configured for static generation during build.\n9. Test with various date parameters and verify correct data display.\n10. Add appropriate error handling for invalid dates or missing data.",
            "status": "pending",
            "parentTaskId": 14
          },
          {
            "id": 2,
            "title": "Implement monthly report view page and components",
            "description": "Create the monthly report view page with aggregated statistics and AI-generated summaries for monthly time periods.",
            "dependencies": [],
            "details": "1. Create a new page at `/monthly/[[...date]]` that accepts an optional date parameter.\n2. Implement the page layout with sections for statistics and summary content.\n3. Create a data fetching function to retrieve monthly aggregated statistics based on the provided date (or default to current month).\n4. Implement a component to render the monthly summary markdown from `data/<repoName>/summaries/month/yyyy-mm.md` using react-markdown or Next.js MDX support.\n5. Add navigation controls to move between different months.\n6. Create visualization components for key monthly metrics using an appropriate charting library.\n7. Implement fallback UI for missing data or summaries.\n8. Ensure the page is configured for static generation during build.\n9. Test with various date parameters and verify correct data display.\n10. Add appropriate error handling for invalid dates or missing data.",
            "status": "pending",
            "parentTaskId": 14
          },
          {
            "id": 3,
            "title": "Implement unified navigation and report view integration",
            "description": "Create a unified navigation system between daily, weekly, and monthly reports and ensure consistent UI/UX across all report views.",
            "dependencies": [1, 2],
            "details": "1. Create a shared navigation component that allows switching between daily, weekly, and monthly views.\n2. Implement date synchronization so that switching between views maintains the selected time period (e.g., switching from weekly to monthly view should show the month containing the selected week).\n3. Create shared UI components for consistent styling across all report views.\n4. Implement a unified data fetching layer that can be used by all report views.\n5. Add breadcrumb navigation to show the current time period and context.\n6. Create a shared layout component that wraps all report views for consistent UI.\n7. Implement URL synchronization so the URL always reflects the current view and time period.\n8. Add keyboard shortcuts for navigating between time periods and views.\n9. Ensure responsive design works consistently across all report views.\n10. Test navigation flows between different report views and time periods.\n11. Add appropriate loading states and transitions between views.",
            "status": "pending",
            "parentTaskId": 14
          },
          {
            "id": 4,
            "title": "Implement daily report view page and components",
            "description": "Create the daily report view page with aggregated statistics and AI-generated summaries for daily time periods.",
            "details": "1. Create a page at `/daily/[[...date]]` that accepts an optional date parameter.\n2. Implement the page layout with sections for statistics and summary content.\n3. Create a data fetching function to retrieve daily statistics based on the provided date (or default to latest date).\n4. Add navigation controls to move between different days.\n5. Create visualization components for key daily metrics.\n6. Implement fallback UI for missing data or summaries.\n7. Ensure the page is configured for static generation during build.\n8. Test with various date parameters and verify correct data display.\n9. Add appropriate error handling for invalid dates or missing data.",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 14
          }
        ]
      },
      {
        "id": 15,
        "title": "Set up CI/CD workflows and data management",
        "description": "Implement GitHub Actions workflows for automation and set up the data branch management strategy.",
        "status": "done",
        "dependencies": [10, 12, 13],
        "priority": "low",
        "details": "Create GitHub Actions workflows in `.github/workflows/`: `run-pipelines.yml` for daily pipeline execution, `pr-checks.yml` for code quality checks, and `deploy.yml` for website deployment. Implement custom actions for database management (`restore-db`, `pipeline-data`). Set up the `_data` branch strategy for storing historical data and database dumps. Create the data synchronization utility (`data:sync`) to allow developers to sync with production data. Implement error handling and notifications for workflow failures. Add documentation for the CI/CD process and data management strategy.",
        "testStrategy": "Test each GitHub Actions workflow to verify it runs correctly. Test the data branch management by simulating pipeline runs and checking that data is correctly stored and retrieved. Test the data synchronization utility to ensure it correctly syncs local environments with production data. Verify error handling by simulating failures in different parts of the workflows."
      },
      {
        "id": 16,
        "title": "Implement Database Schema for Activity-Centric Scoring System",
        "description": "Design and implement database schema changes to support the activity-centric scoring system, including new tables for different score types and activity tagging functionality.",
        "details": "This task involves creating and modifying database schema to support the activity-centric scoring system with the following requirements:\n\n1. Create new score tables:\n   - `prScores`: Store pull request activity scores with columns for user_id, pr_id, score_value, timestamp, and any relevant metadata\n   - `issueScores`: Store issue-related activity scores with columns for user_id, issue_id, score_value, timestamp, and metadata\n   - `reviewScores`: Store code review activity scores with columns for user_id, review_id, score_value, timestamp, and metadata\n   - Each table should have appropriate primary keys and foreign key constraints\n   - Include created_at and updated_at timestamp fields\n   - Consider adding an activity_type field for categorization\n\n2. Create the `activityTags` table:\n   - Columns: id, activity_id, activity_type, tag_id, created_at, updated_at\n   - This table will serve as a polymorphic join table linking different activity types to tags\n   - Implement proper indexing for efficient querying\n\n3. Modify existing tables as needed:\n   - Update any tables that will interact with the new scoring system\n   - Add foreign key relationships where appropriate\n   - Ensure backward compatibility with existing data\n\n4. Create database migrations:\n   - Write migration scripts for creating new tables\n   - Write migration scripts for modifying existing tables\n   - Include rollback functionality for all migrations\n\n5. Update database documentation:\n   - Document the new schema design\n   - Update entity-relationship diagrams\n   - Document the relationships between tables",
        "testStrategy": "Testing should verify the database schema changes are correctly implemented and functioning as expected:\n\n1. Migration Testing:\n   - Verify migrations run successfully in development environment\n   - Test rollback functionality to ensure it properly reverts changes\n   - Verify migrations run successfully on a copy of production data\n\n2. Schema Validation:\n   - Confirm all new tables are created with correct columns, data types, and constraints\n   - Verify foreign key relationships are properly established\n   - Check that indexes are created correctly for performance\n\n3. Data Integrity Testing:\n   - Insert test data into new tables and verify it can be retrieved correctly\n   - Test the polymorphic relationships in the activityTags table by linking various activity types to tags\n   - Verify cascading updates/deletes work as expected for related records\n\n4. Query Performance Testing:\n   - Create and run common queries that will be used by the application\n   - Verify query performance is acceptable using EXPLAIN ANALYZE\n   - Test with larger datasets to ensure scalability\n\n5. Integration Testing:\n   - Test the schema changes with any existing ORM models\n   - Verify application code can successfully interact with the new schema\n   - Test any API endpoints that will use the new tables",
        "status": "pending",
        "dependencies": [],
        "priority": "high"
      },
      {
        "id": 17,
        "title": "Update Pipeline Configuration for Activity-Centric Scoring System",
        "description": "Restructure the pipeline configuration to implement an activity-centric scoring system that calculates scores based on individual activities with customizable parameters and tag modifiers.",
        "details": "This task involves updating the pipeline configuration files to support the new activity-centric scoring approach. Specifically:\n\n1. Modify the config structure to include a new 'activities' section that defines scoring rules for each activity type:\n   - Each activity should have a 'baseScore' parameter defining its default value\n   - Include 'tagBonus' configurations that specify score multipliers or additive bonuses for activities with specific tags\n   - Define score decay or expiration rules if applicable\n\n2. Update the 'scoring' section to reference these activity-specific rules and define how individual activity scores are aggregated into overall user scores\n\n3. Enhance the 'tags' section to include metadata about each tag type, including:\n   - Tag categories (e.g., skill-based, quality-based, difficulty-based)\n   - Tag weights or importance factors\n   - Tag relationships (parent/child relationships if applicable)\n\n4. Add configuration options for score normalization and capping to prevent exploitation\n\n5. Include documentation within the configuration files explaining the scoring formula and how different parameters affect the final score\n\n6. Ensure backward compatibility or provide migration scripts for existing configurations\n\nThe configuration should be in YAML or JSON format, consistent with existing pipeline configurations.",
        "testStrategy": "Testing should verify that the updated configuration properly supports the activity-centric scoring system:\n\n1. Unit tests:\n   - Validate that the configuration parser correctly loads and interprets the new structure\n   - Test that all required fields are validated (error on missing required fields)\n   - Verify that default values are applied when optional fields are omitted\n\n2. Integration tests:\n   - Create test configurations with various activity types and tag combinations\n   - Verify that the scoring pipeline correctly applies baseScore and tagBonus modifiers\n   - Test edge cases including activities with multiple tags, extreme score values, etc.\n\n3. Regression tests:\n   - Ensure that existing functionality continues to work with the new configuration\n   - Compare scores calculated with old and new configurations for the same input data\n\n4. Configuration validation tests:\n   - Create a schema validator that confirms all configurations adhere to the new structure\n   - Test with intentionally malformed configurations to ensure proper error handling\n\n5. Performance tests:\n   - Measure any impact on configuration loading time or memory usage\n   - Verify that complex scoring rules don't significantly impact processing speed",
        "status": "pending",
        "dependencies": [16],
        "priority": "high"
      }
    ],
    "metadata": {
      "created": "2025-01-27T00:00:00.000Z",
      "updated": "2025-01-27T00:00:00.000Z",
      "description": "Main task list"
    }
  },
  "scoring-v2": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Database Schema for Activity-Centric Scoring System",
        "description": "Design and implement comprehensive database schema changes to support activity-centric scoring with new tables for different score types and activity tagging functionality.",
        "details": "1. Create new scoring tables:\n   - `prScores` table with columns: id (PK), user_id (FK), pr_id (FK), score_value (DECIMAL), activity_type (VARCHAR), created_at, updated_at\n   - `issueScores` table with columns: id (PK), user_id (FK), issue_id (FK), score_value (DECIMAL), activity_type (VARCHAR), created_at, updated_at\n   - `reviewScores` table with columns: id (PK), user_id (FK), review_id (FK), score_value (DECIMAL), activity_type (VARCHAR), created_at, updated_at\n   - Add proper indexes on user_id, foreign key columns, and created_at for efficient querying\n\n2. Create `activityTags` polymorphic join table:\n   - Columns: id (PK), activity_id (INT), activity_type (ENUM: 'pr', 'issue', 'review'), tag_id (FK), created_at, updated_at\n   - Composite index on (activity_id, activity_type) and index on tag_id\n   - Foreign key constraint to tags table\n\n3. Database migrations:\n   - Create up/down migration files for each new table\n   - Include proper foreign key constraints and indexes\n   - Add rollback functionality for safe deployment\n   - Test migrations on sample data\n\n4. Schema documentation:\n   - Update ER diagrams showing relationships between new tables\n   - Document polymorphic relationship pattern used in activityTags\n   - Include examples of how tables relate to existing user and repository data",
        "testStrategy": "1. Migration testing:\n   - Run migrations on development database and verify table creation\n   - Test rollback functionality to ensure clean reversal\n   - Validate all foreign key constraints are properly enforced\n\n2. Data integrity testing:\n   - Insert sample data into each new table\n   - Verify foreign key relationships prevent invalid data insertion\n   - Test polymorphic relationships in activityTags table work correctly\n\n3. Performance testing:\n   - Query performance tests on indexed columns\n   - Test join queries between new tables and existing user/repository tables\n   - Validate composite indexes on activityTags perform efficiently\n\n4. Schema validation:\n   - Compare implemented schema against design requirements\n   - Verify all required columns and constraints are present\n   - Test backward compatibility with existing application code",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Score Tables for Different Activity Types",
            "description": "Implement the database tables for storing different types of activity scores including prScores, issueScores, and reviewScores with appropriate schema design.",
            "details": "Implementation steps:\n1. Create the `prScores` table with columns:\n   - id (primary key)\n   - user_id (foreign key to users table)\n   - pr_id (foreign key to pull requests table)\n   - score_value (numeric/decimal)\n   - activity_type (varchar, for categorization)\n   - metadata (json/jsonb for flexible storage)\n   - timestamp (when the score was earned)\n   - created_at, updated_at (timestamps)\n\n2. Create the `issueScores` table with columns:\n   - id (primary key)\n   - user_id (foreign key to users table)\n   - issue_id (foreign key to issues table)\n   - score_value (numeric/decimal)\n   - activity_type (varchar, for categorization)\n   - metadata (json/jsonb)\n   - timestamp (when the score was earned)\n   - created_at, updated_at (timestamps)\n\n3. Create the `reviewScores` table with columns:\n   - id (primary key)\n   - user_id (foreign key to users table)\n   - review_id (foreign key to reviews table)\n   - score_value (numeric/decimal)\n   - activity_type (varchar, for categorization)\n   - metadata (json/jsonb)\n   - timestamp (when the score was earned)\n   - created_at, updated_at (timestamps)\n\n4. Add appropriate indexes for each table:\n   - Index on user_id for efficient user-based queries\n   - Index on activity_type for filtering\n   - Composite indexes for common query patterns\n\nTesting approach:\n- Write unit tests to verify table creation\n- Test foreign key constraints by attempting invalid inserts\n- Verify indexes are created correctly\n- Test inserting and retrieving sample data for each table",
            "status": "pending",
            "dependencies": [],
            "parentTaskId": 1
          },
          {
            "id": 2,
            "title": "Implement ActivityTags Table and Polymorphic Relationships",
            "description": "Create the activityTags table with polymorphic associations to connect different activity types with tags, enabling flexible activity categorization.",
            "details": "Implementation steps:\n1. Create the `activityTags` table with columns:\n   - id (primary key)\n   - activity_id (integer, part of polymorphic relationship)\n   - activity_type (varchar, identifies which activity table to reference)\n   - tag_id (foreign key to tags table)\n   - created_at, updated_at (timestamps)\n\n2. Create a `tags` table if it doesn't already exist:\n   - id (primary key)\n   - name (varchar, unique)\n   - description (text, optional)\n   - created_at, updated_at (timestamps)\n\n3. Add appropriate indexes to the `activityTags` table:\n   - Index on (activity_id, activity_type) for efficient polymorphic lookups\n   - Index on tag_id for tag-based filtering\n   - Composite index on (activity_type, tag_id) for common queries\n\n4. Implement foreign key constraint from tag_id to the tags table\n\n5. Create database functions or procedures if needed to simplify working with the polymorphic relationship\n\nTesting approach:\n- Test creating tags and associating them with different activity types\n- Verify polymorphic queries work correctly across different activity tables\n- Test the performance of common queries using the indexes\n- Verify referential integrity with the tags table",
            "status": "pending",
            "dependencies": ["1.1"],
            "parentTaskId": 1
          },
          {
            "id": 3,
            "title": "Create Migration Scripts and Update Documentation",
            "description": "Develop database migration scripts for all schema changes, implement rollback functionality, and update database documentation including ER diagrams.",
            "details": "Implementation steps:\n1. Create forward migration scripts:\n   - Script for creating prScores, issueScores, and reviewScores tables\n   - Script for creating activityTags and tags tables (if needed)\n   - Scripts for any modifications to existing tables\n   - Add appropriate indexes and constraints\n\n2. Create rollback migration scripts:\n   - Script to revert all table creations\n   - Script to revert any modifications to existing tables\n   - Ensure data integrity during rollbacks\n\n3. Test migrations:\n   - Test forward migrations on a development database\n   - Test rollback functionality\n   - Verify all constraints and indexes are properly created\n\n4. Update database documentation:\n   - Create or update entity-relationship (ER) diagrams showing the new tables and their relationships\n   - Document the purpose of each table and its columns\n   - Document the polymorphic relationship pattern used for activity tagging\n   - Document indexing strategy and query patterns\n   - Update any existing schema documentation to reflect changes\n\n5. Create a database seeding script with sample data for testing\n\nTesting approach:\n- Run migrations on a clean database and verify all objects are created correctly\n- Test rollback functionality and verify the database returns to its previous state\n- Verify documentation accuracy by comparing with actual database schema\n- Have another team member review the documentation for clarity and completeness",
            "status": "pending",
            "dependencies": ["1.1", "1.2"],
            "parentTaskId": 1
          }
        ]
      },
      {
        "id": 2,
        "title": "Update Pipeline Configuration for Activity-Centric Scoring System",
        "description": "Restructure pipeline configuration files to implement activity-centric scoring with customizable parameters, tag modifiers, and score aggregation rules.",
        "details": "1. Create new 'activities' configuration section:\n   - Define baseScore for each activity type (pr_creation, pr_merge, issue_creation, issue_resolution, code_review, etc.)\n   - Configure tagBonus rules with multipliers and additive bonuses for specific tags\n   - Set up score decay/expiration rules with configurable time windows\n\n2. Update 'scoring' section:\n   - Define aggregation methods (sum, weighted_average, max, etc.)\n   - Configure time-based scoring windows and decay functions\n   - Set up user-level score calculation from individual activities\n\n3. Enhance 'tags' section:\n   - Add tag categories (skill: 'frontend', 'backend'; quality: 'critical', 'enhancement'; difficulty: 'easy', 'hard')\n   - Define tag weights and importance factors\n   - Configure parent/child tag relationships\n\n4. Add score normalization:\n   - Set score caps per activity type and time period\n   - Configure anti-gaming measures (rate limiting, diminishing returns)\n   - Define score normalization algorithms\n\n5. Include inline documentation:\n   - Document scoring formulas in YAML/JSON comments\n   - Provide examples of score calculations\n   - Add parameter explanation and valid value ranges\n\n6. Create migration utilities:\n   - Build configuration validation scripts\n   - Develop backward compatibility layer\n   - Create migration tools for existing configs",
        "testStrategy": "1. Configuration validation:\n   - Validate YAML/JSON syntax and schema compliance\n   - Test all scoring parameter combinations\n   - Verify tag relationship integrity and circular dependency detection\n\n2. Scoring calculation testing:\n   - Create test scenarios with various activity combinations\n   - Verify score aggregation accuracy across different time windows\n   - Test edge cases (zero scores, maximum caps, expired activities)\n\n3. Migration testing:\n   - Test backward compatibility with existing configurations\n   - Validate migration scripts on sample legacy configs\n   - Ensure graceful fallback for missing parameters\n\n4. Performance testing:\n   - Benchmark configuration loading times\n   - Test memory usage with large tag hierarchies\n   - Validate configuration parsing efficiency",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-02T20:09:05.475Z",
      "updated": "2025-07-02T20:09:42.597Z",
      "description": "Activity-centric scoring system v2 implementation"
    }
  },
  "multi-repo-frontend": {
    "tasks": [
      {
        "id": 1,
        "title": "Refactor Overall Project Summary Page for Aggregated View",
        "description": "Refactor the existing summary pages at `/day`, `/week`, and `/month` to display aggregated data from all tracked repositories. This involves updating data queries to sum metrics project-wide and fetch a global summary instead of a repository-specific one.",
        "details": "1. **Modify `getIntervalSummaryContent` Query:** In `src/app/[interval]/[[...date]]/queries.ts`, update the `getIntervalSummaryContent` function to remove the repository ID parameter and fetch content from the `overallSummaries` table.\n2. **Aggregate `getMetricsForInterval`:** Ensure the `getMetricsForInterval` query correctly aggregates statistics (contributor counts, PR/issue totals, lines of code) across all repositories for the selected time interval.\n3. **Update Modal Content:** Modify the modals for Stat Cards (Contributors, Pull Requests, Issues) to display aggregated lists from all repositories.",
        "testStrategy": "1. Load the `/day`, `/week`, and `/month` pages and verify that the displayed statistics are the sum of all repositories.\n2. Click on the 'Contributors', 'Pull Requests', and 'Issues' stat cards to open their respective modals.\n3. Confirm that the modal content is an aggregated list of items from across the entire project ecosystem for the selected time frame.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Repository List Page",
        "description": "Create a new page at `/repos` to display a list of all tracked repositories, sorted by the number of unique contributors over the last three months. Each repository will be represented by a card showing key information.",
        "details": "1. **Create Page Component:** Create a new Next.js page at `src/app/repos/page.tsx`.\n2. **Develop New Query:** Implement a new query that fetches a list of all repositories, sorted by unique contributor count in the last 90 days (descending). For each repository, the query must also return its name, owner, top 3 all-time contributors, and a time-series of weekly commit counts for the last 90 days.\n3. **Build `RepositoryCard` Component:** Create a reusable React component for the repository card. It should display: `{owner}/{name}`, avatars of the top 3 contributors, and a simple line graph for weekly commits using shadcn/ui and Tailwind CSS.",
        "testStrategy": "1. Navigate to the `/repos` URL.\n2. Verify that the page displays a list of repository cards.\n3. Check that the list is sorted correctly, with the repositories having the most contributors in the last 3 months appearing first.\n4. For each card, confirm the repository name, contributor avatars, and activity graph are displayed correctly.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Repository Detail Page",
        "description": "Create a new dynamic page at `/repos/{owner}/{name}` to display detailed analytics for a single repository. The page will be composed of multiple independently-loading server components, each fetching its own data to allow for streaming with Suspense. The page will feature a two-column layout.",
        "status": "pending",
        "dependencies": [2],
        "priority": "high",
        "details": "1. **Layout Shell:** The main page at `src/app/repos/[owner]/[name]/page.tsx` will serve as a layout shell, defining the two-column structure.\n2. **Component-Scoped Data Fetching:** Instead of a single monolithic query, each section of the page (Header, Summaries, Heatmap, Stats, Contributors, PRs) will be implemented as a separate `async` server component. Each component will be responsible for fetching only the data it needs.\n3. **UI Assembly with Suspense:** The main page will assemble the UI by importing these async components and wrapping them in `<Suspense>` boundaries. This will enable parts of the page to render and stream to the client as their data becomes available.\n4. **Refactor Existing Components:** The previously created `RepoDetailHeader` will be refactored into an async component that fetches its own data, and the monolithic `getRepoProfile` query will be broken apart.",
        "testStrategy": "1. Navigate to a repository detail page, e.g., `/repos/elizaos/eliza`.\n2. Verify that all sections (header, summaries, heatmap, etc.) load and display the correct data specific to that repository.\n3. Confirm that links to contributor profiles and GitHub PRs are working correctly.\n4. Use browser developer tools to simulate a slow network and verify that page sections stream in independently, with Suspense fallbacks (e.g., skeletons or loaders) being displayed while data is loading.",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Finalize Navigation and Perform End-to-End Testing",
        "description": "Integrate the new repository pages into the main site navigation and conduct end-to-end testing of the new user flow, ensuring all links between pages work as expected.",
        "details": "1. **Add Navigation Link:** In the main site navigation component, add a new link to the Repository List page (`/repos`).\n2. **Link List to Detail:** Ensure that clicking on a `RepositoryCard` on the `/repos` page correctly navigates to its corresponding `/repos/{owner}/{name}` detail page.\n3. **Verify All Links:** Perform a full review of the new pages to ensure all internal and external links (e.g., to GitHub, to user profiles) are functional.",
        "testStrategy": "1. Start at the main summary page and click the new 'Repositories' navigation link.\n2. From the `/repos` list page, click on a repository to navigate to its detail page.\n3. From the repository detail page, click on a contributor's name to navigate to their user profile page.\n4. Verify that the entire flow is smooth, all pages load correctly, and all data is consistent.",
        "priority": "medium",
        "dependencies": [1, 4],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-02T23:49:26.014Z",
      "updated": "2025-07-18T22:39:54.323Z",
      "description": "Tasks for multi-repo-frontend context"
    }
  }
}
